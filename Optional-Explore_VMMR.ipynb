{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notices**\n",
    "\n",
    "Copyright (c) 2019 Intel Corporation.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining\n",
    "a copy of this software and associated documentation files (the\n",
    "\"Software\"), to deal in the Software without restriction, including\n",
    "without limitation the rights to use, copy, modify, merge, publish,\n",
    "distribute, sublicense, and/or sell copies of the Software, and to\n",
    "permit persons to whom the Software is furnished to do so, subject to\n",
    "the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be\n",
    "included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore VMMRdb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Understand ways to find a data set and to analyze a data set to have more in depth information about the dataset before we start any preprocessing or training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities \n",
    "**In this section of the training you will**\n",
    "- Fetch and visually inspect a dataset \n",
    "\n",
    "As you follow this notebook, complete **Activity** sections to finish this workload. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a Dataset\n",
    "\n",
    "Artificial intelligence projects depend upon data. When beginning a project, data scientists look for existing data sets that are similar to or match the given problem. This saves time and money, and leverages the work of others, building upon the body of knowledge for all future projects. \n",
    "\n",
    "Typically you begin with a search engine query. For this project, we were looking for a data set with an unencumbered license.\n",
    "\n",
    "This project starts with [Vehicle Make and Model Recognition Dataset (VMMRdb)](http://vmmrdb.cecsresearch.org/)   which is large in scale and diversity, containing 9,170 classes consisting of 291,752 images, covering models manufactured between 1950 to 2016. VMMRdb dataset contains images that were taken by different users, different imaging devices, and multiple view angles, ensuring a wide range of variations to account for various scenarios that could be encountered in a real-life scenario. The cars are not well aligned, and some images contain irrelevant background. The data covers vehicles from 712 areas covering all 412 sub-domains corresponding to US metro areas. VMMRdb dataset can be used as a baseline for training a robust model in several real-life scenarios for traffic surveillance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch & Inspect Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will look at the dataset with its subdirectories to create a simple frequency analysis of the dataset. We'll use simple frequency distributions to familiriaze ourself with the dataset and its structure. Before running this cell, download VMMRdb and unzip it into a folder named **VMMR**. \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Fetch and Inspect your data\n",
    "import os\n",
    "import glob\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "#Path to unzipped 9170 classes folder\n",
    "cwd = os.getcwd()\n",
    "d = cwd + '/SubsetVMMR'\n",
    "\n",
    "folder_list = [os.path.join(d, o) for o in os.listdir(d) \n",
    "                    if os.path.isdir(os.path.join(d,o))]\n",
    "\n",
    "#Create all files in a list\n",
    "file_list = glob.glob(\"SubsetVMMR/*/*\")\n",
    "\n",
    "#Create list of class names\n",
    "class_name_list = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "\n",
    "#Create a tree structure of the dataset \n",
    "class_dict = defaultdict(dict)\n",
    "for tmp in class_name_list:\n",
    "    model = \"_\".join(tmp.split(\"_\")[:-1])\n",
    "    car_make = tmp.split(\"_\")[0]\n",
    "    if car_make not in class_dict:\n",
    "        class_dict[car_make] = {}\n",
    "        class_dict[car_make][model] = {}\n",
    "        class_dict[car_make][model][tmp] = len(os.listdir(os.path.join(d, tmp)))\n",
    "    elif model not in class_dict[car_make]:\n",
    "            class_dict[car_make][model] = {}\n",
    "            class_dict[car_make][model][tmp] = len(os.listdir(os.path.join(d, tmp)))\n",
    "    else:\n",
    "        class_dict[car_make][model][tmp] = len(os.listdir(os.path.join(d, tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Car Make Distribution\n",
    "\n",
    "After creating a tree structured representation of the dataset considering its manufacturer, model, year distribution, we look at the visually interactive plots to make comparisons among different classes. The distribution below provides car make variation in the VMMRdb. The number corresponds to each car make represents the available number of car models with different years in VMMRdb. For example, **chevrolet** has 1013 different numbers of model and year variation in the database. \n",
    "\n",
    "In order to be able to control the graphs below, install ipywidgets and enable them on jupyter notebook if you have not done so. To achieve this task, you can uncomment the cell below and run it. If you already have ipywidgets and it's enabled, you can skip this step and move to next cell. \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "#Create function to display interactive plotting\n",
    "import collections\n",
    "import operator\n",
    "import pygal\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact\n",
    "\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "\n",
    "#Check only the Manufacturer Distribution among 9170 classes\n",
    "tmp_dict = {}\n",
    "for element in class_name_list:\n",
    "    tmp = element.split(\"_\")[0]\n",
    "    if tmp in tmp_dict:\n",
    "        tmp_dict[tmp] += 1\n",
    "    else:\n",
    "        tmp_dict[tmp] = 1\n",
    "#Sort the car makes\n",
    "tmp_dict = collections.OrderedDict(sorted(tmp_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "def f(Car_Make_Number=10):\n",
    "    line_chart = pygal.HorizontalBar()\n",
    "    line_chart.title = 'Car Make Distribution'\n",
    "    x = 0\n",
    "    for keys in tmp_dict:\n",
    "        line_chart.add(keys, tmp_dict[keys])\n",
    "        x += 1\n",
    "        if x>=Car_Make_Number:\n",
    "            break;\n",
    "    galplot(line_chart)\n",
    "interact(f, Car_Make_Number=(1, len(tmp_dict),1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Car Model Distribution\n",
    "Now that we know the car make distribution in the database, we can take a closer look at car model distribution. By looking at the distribution of car models we want to understand which models have most number of images with the combination of year variation. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "In the cell below, update **Car_Brand** with the interest of your car manufacturer and **Run** to see the number of images in each model. \n",
    "\n",
    "Example: Car_Brand = \"honda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Car_Brand = \"chevrolet\"\n",
    "tmp = class_dict[Car_Brand]\n",
    "tmp_dict = {}\n",
    "for tmp2 in tmp:\n",
    "    tmp_dict[tmp2] = sum(tmp[tmp2].values())\n",
    "tmp_dict = collections.OrderedDict(sorted(tmp_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "def class_dist_plot(Car_Model_Number = 5):\n",
    "    pie_chart = pygal.Pie(inner_radius= 0.4)\n",
    "    tmp3 = Car_Brand + \" \" + \"car models distribution\" \n",
    "    pie_chart.title = tmp3\n",
    "    x=0\n",
    "    for tmp2 in tmp_dict:\n",
    "        pie_chart.add(tmp2, tmp_dict[tmp2])\n",
    "        x += 1\n",
    "        if x>=Car_Model_Number:\n",
    "            break;\n",
    "    galplot(pie_chart)    \n",
    "interact(class_dist_plot, Car_Model_Number=(1, len(tmp_dict),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Car Year Distribution\n",
    "We now know the variation of car makes, and models. With this activity, we can compare the specific car model on its year distribution. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "In order to yearly check data distribution, class_dist_plot function is created. It's taking two variables one of which is the choice of Car manufacturer: **Car_Brand** and car model: **Car_Model**. \n",
    "\n",
    "Update these two variables and hit **Run**. Example: Car_Brand = \"honda\", Car_Model = \"honda_pilot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "Car_Brand = \"honda\"\n",
    "Car_Model = \"honda_civic\"\n",
    "tmp = class_dict[Car_Brand][Car_Model]\n",
    "#Sort based on the year and create a plot\n",
    "od = collections.OrderedDict(sorted(tmp.items()))\n",
    "def class_dist_plot(start_year, end_year):\n",
    "    dot_chart = pygal.Dot(x_label_rotation=45)\n",
    "    dot_chart.title = \" \".join(Car_Model.split(\"_\")) + \" year distribution\"\n",
    "    dot_chart.x_labels = [tmp2.split(\"_\")[-1] for tmp2 in od if int(tmp2.split(\"_\")[-1])>=start_year and \n",
    "                         int(tmp2.split(\"_\")[-1])<=end_year]\n",
    "    dot_chart.add(Car_Model, [od[tmp2] for tmp2 in od if int(tmp2.split(\"_\")[-1])>=start_year and \n",
    "                         int(tmp2.split(\"_\")[-1])<=end_year])\n",
    "    galplot(dot_chart)\n",
    "start_tmp = int(list(od.keys())[0].split(\"_\")[-1])\n",
    "end_tmp = int(list(od.keys())[-1].split(\"_\")[-1])\n",
    "interact(class_dist_plot, start_year=(start_tmp, end_tmp,1), end_year=(start_tmp, end_tmp, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Display Random Images\n",
    "The activities so far included in this notebook aim at having a better understanding of car make model year distribution. We can also take a look at some random images in the dataset to further explore how the images vary in the database.  \n",
    "\n",
    "**Activity**\n",
    "\n",
    "In the cell below, update the display_images function by changing the **numOfImages** parameter to a number from 1 to 5. Then, hit **Run**. \n",
    "\n",
    "Example: numOfImages = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "def display_images(file_list, numOfImages = 5):\n",
    "    indicies = random.sample(range(len(file_list)), numOfImages * numOfImages)    \n",
    "    fig, axes = plt.subplots(nrows=numOfImages,ncols=numOfImages, figsize=(15,15), sharex=True, sharey=True, frameon=False)\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        #Pick a random picture from the file list\n",
    "        imgplot = mpimg.imread(file_list[indicies[i]], 0)\n",
    "        ax.imshow(imgplot)\n",
    "        ax.text(10,20,file_list[indicies[i]].split(\"/\")[-2], fontdict={\"backgroundcolor\": \"black\",\"color\": \"white\" })\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(h_pad=0, w_pad=0)            \n",
    "display_images(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "TensorFlow* Optimizations on Modern Intel® Architecture, https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\n",
    "\n",
    "Intel Optimized TensorFlow Wheel Now Available, https://software.intel.com/en-us/articles/intel-optimized-tensorflow-wheel-now-available\n",
    "\n",
    "Build and Install TensorFlow* on Intel® Architecture, https://software.intel.com/en-us/articles/build-and-install-tensorflow-on-intel-architecture\n",
    "\n",
    "TensorFlow, https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Studies\n",
    "\n",
    "Manufacturing Package Fault Detection Using Deep Learning, https://software.intel.com/en-us/articles/manufacturing-package-fault-detection-using-deep-learning\n",
    "\n",
    "Automatic Defect Inspection Using Deep Learning for Solar Farm, https://software.intel.com/en-us/articles/automatic-defect-inspection-using-deep-learning-for-solar-farm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "A Large and Diverse Dataset for Improved Vehicle Make and Model Recognition\n",
    "F. Tafazzoli, K. Nishiyama and H. Frigui\n",
    "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops 2017. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
